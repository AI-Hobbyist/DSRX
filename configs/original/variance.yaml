base_config:
  - configs/base.yaml

task_cls: training.variance_task.VarianceTask

dictionaries:
  zh: dictionaries/opencpop-extension-triple-2.txt
  ja: dictionaries/jpn.txt
extra_phonemes: []
merged_phoneme_groups: 
    - ['ja/Edge', 'ja/cl', 'zh/cl']
datasets:
  - raw_data_dir: 'data/117'
    speaker: 117
    spk_id: 0
    language: zh
    test_prefixes:
      - '64_budebuai_seg015'
      - '71_mingrizange_seg042'

  - raw_data_dir: 'data/hiro Ja'
    speaker: hiro
    spk_id: 1
    language: ja
    test_prefixes:
      - '化作青烟 (1)_011'
      - '終着_011'

  - raw_data_dir: 'data/kiritan'
    speaker: kiritan
    spk_id: 2
    language: ja
    test_prefixes:
      - '01_seg008'
      - '04_seg012'

  - raw_data_dir: 'data/liliko'
    speaker: liliko
    spk_id: 3
    language: zh
    test_prefixes:
      - 'hanser_908_0'
      - 'hanser_973_0'

  - raw_data_dir: 'data/rintaku_masaru'
    speaker: rintaku
    spk_id: 4
    language: ja

  - raw_data_dir: 'data/sansha'
    speaker: sansha
    spk_id: 5
    language: zh

  - raw_data_dir: 'data/shenluxiao_JPN'
    speaker: shenluxiao
    spk_id: 6
    language: ja
    
  - raw_data_dir: 'data/weina'
    speaker: weina
    spk_id: 7
    language: ja

  - raw_data_dir: 'data/xiaoran'
    speaker: xiaoran
    spk_id: 8
    language: zh

  - raw_data_dir: 'data/xuanzhuan_ACE/raw'
    speaker: xuanzhuan
    spk_id: 9
    language: zh

  - raw_data_dir: 'data/yoko/diffsinger_db'
    speaker: yoko
    spk_id: 10
    language: ja

  - raw_data_dir: 'data/ichika'
    speaker: ichika
    spk_id: 11
    language: ja

  - raw_data_dir: 'data/moqi_diffsinger'
    speaker: moqi
    spk_id: 12
    language: zh
    test_prefixes:
      - 'moqi_岁月成碑_岁月成碑 moqi voice_seg025'

  - raw_data_dir: 'data/qiguanmo'
    speaker: qiguanmo
    spk_id: 13
    language: zh
    test_prefixes:
      - '世末歌者_世末歌者干音_Audio 2.cm-St_seg013'

audio_sample_rate: 44100
hop_size: 512            # Hop size.
fft_size: 2048           # FFT size.
win_size: 2048           # FFT size.
midi_smooth_width: 0.06  # in seconds

binarization_args:
  shuffle: true
  num_workers: 40
  prefer_ds: false
  allow_missing_phonemes: true

binary_data_dir: 'data/opencpop_variance/binary'
binarizer_cls: preprocessing.variance_binarizer.VarianceBinarizer

use_lang_id: true
num_lang: 2
use_spk_id: true
enc_ffn_kernel_size: 3
use_rope: true
num_spk: 14
predict_dur: false
predict_pitch: false
predict_energy: false
predict_breathiness: true
predict_voicing: true
predict_tension: true

rel_pos: true
hidden_size: 256

dur_prediction_args:
  arch: resnet
  hidden_size: 256
  dropout: 0.1
  num_layers: 5
  kernel_size: 3
  log_offset: 1.0
  loss_type: mse
  lambda_pdur_loss: 0.3
  lambda_wdur_loss: 1.0
  lambda_sdur_loss: 3.0

use_melody_encoder: false
melody_encoder_args:
  hidden_size: 128
  enc_layers: 4
use_glide_embed: false
glide_types: [up, down]
glide_embed_scale: 11.313708498984760  # sqrt(128)

pitch_prediction_args:
  pitd_norm_min: -8.0
  pitd_norm_max: 8.0
  pitd_clip_min: -12.0
  pitd_clip_max: 12.0
  repeat_bins: 64
  backbone_type: 'lynxnet2'
  backbone_args:
    num_layers: 6
    num_channels: 512
    dropout_rate: 0.0 

energy_db_min: -96.0
energy_db_max: -12.0
energy_smooth_width: 0.12

breathiness_db_min: -96.0
breathiness_db_max: -20.0
breathiness_smooth_width: 0.12
voicing_db_min: -96.0
voicing_db_max: -12.0
voicing_smooth_width: 0.12

tension_logit_min: -10.0
tension_logit_max: 10.0
tension_smooth_width: 0.12

variances_prediction_args:
  total_repeat_bins: 48
  backbone_type: 'lynxnet2'
  backbone_args:
    num_layers: 6
    num_channels: 384
    dropout_rate: 0.0

lambda_dur_loss: 1.0
lambda_pitch_loss: 1.0
lambda_var_loss: 1.0

diffusion_type: reflow  # ddpm
time_scale_factor: 1000
schedule_type: 'linear'
K_step: 1000
timesteps: 1000
max_beta: 0.02
main_loss_type: l2
main_loss_log_norm: true
sampling_algorithm: euler
sampling_steps: 20
diff_accelerator: ddim
diff_speedup: 10

# train and eval
num_sanity_val_steps: 1
optimizer_args:
  optimizer_cls: modules.optimizer.muon.Muon_AdamW
  lr: 0.0006
  muon_args:
    weight_decay: 0.1
  adamw_args:
    weight_decay: 0.0
lr_scheduler_args:
  step_size: 5000
  gamma: 0.8
max_batch_frames: 80000
max_batch_size: 64
dataset_size_key: 'lengths'
val_check_interval: 2000
num_valid_plots: 10
max_updates: 100000
num_ckpt_keep: 5
permanent_ckpt_start: 60000
permanent_ckpt_interval: 10000

finetune_enabled: false
finetune_ckpt_path: null
finetune_ignored_params:
  - model.spk_embed
  - model.fs2.txt_embed

# LoRA fine-tuning (optional)
lora:
  enabled: false
  rank: 8
  alpha: 16
  target_modules: [linear]
  base_ckpt: ""
  train_bias: false
  merge_before_export: true
  - model.fs2.encoder.embed_tokens
finetune_strict_shapes: true

freezing_enabled: false
frozen_params: []
